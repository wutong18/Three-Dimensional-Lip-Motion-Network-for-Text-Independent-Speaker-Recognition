# Three-Dimensional-Lip-Motion-Network-for-Text-Independent-Speaker-Recognition

The purpose of this work is to use the speaker's 3D lip motion to recognize the speakers.

Our methods are evaluated on a Mandarin Dataset, which is a large-scale depth-based multimodal audio-visual corpus, including 3D lip points of 68 speakers. 

Here is the quote of this dataset.

'''

python 
int m
'''
  
@INPROCEEDINGS {8622884,
author = {J. Wang and L. Wang and J. Zhang and J. Wei and M. Yu and R. Yu},
booktitle = {2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)},
title = {A Large-Scale Depth-Based Multimodal Audio-Visual Corpus in Mandarin},
year = {2018},
volume = {},
issn = {},
pages = {881-885},
keywords = {speech recognition;databases;three-dimensional displays;feature extraction;streaming media;cameras;data acquisition},
doi = {10.1109/HPCC/SmartCity/DSS.2018.00146},
url = {https://doi.ieeecomputersociety.org/10.1109/HPCC/SmartCity/DSS.2018.00146},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}
'''
